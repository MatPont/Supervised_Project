
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Visa Premier}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Preliminary Study}

Each sample of this data set corresponds to a client of a bank that is described by its behaviours. The idea is to predict a binary variable corresponding to the fact the client is in possession of the Visa Premier card or not.

\begin{table}[H] 
    \centering
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        & \textbf{\#samples} & \textbf{\#features} & \textbf{\#classes} & \textbf{Balance} \\
        \hline
        Visa Premier & 1073 & 47 & 2 & 0.33 \\
        \hline
    \end{tabular}
    \captionsetup{width=0.8\textwidth}
    \caption{Visa Premier fraud data set description.}
    \label{tab:visa_desc}
\end{table}

The data set is quite imbalanced with almost 2/3 of samples being in the first class (not in possession of the Visa Premier card).



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Pre-processing.}

The variable \textit{matricul} is an identifier and has a unique value for each sample making it not important for our analysis. Moreover, the variable \textit{nbimpaye} has the value of zero for each sample. Therefore, we have decided to remove these variables. The variable \textit{nbbon} and \textit{mtbon} have the same value for each sample except only one, we can consider it as an outlier and remove it and the two variables cited.

Most of the variables are quantitative except 7 that are qualitative:

\begin{itemize}
    \item \textbf{departem}: residency department. 
    \item \textbf{ptvente}: selling point.
    \item \textbf{sexe}: sexe.
    \item \textbf{sitfamil}: marital status.
    \item \textbf{csp}: socio-professional category.
    \item \textbf{sexer}: sexe (binary values)
    \item \textbf{codeqlt}: bank-assessed customer quality (ordinal).
\end{itemize}{}

We see that the variable \textit{sexe} appears twice, one with character values and the other one with binary values. The same comment is true for the variable to predict \textit{cartevpr}. Therefore, we can remove these duplicates and keep the numerical variables.

After this pre-processing the final dataset has the following dimension: $1072 \times 42$ where the last column corresponds to the label.

424 values seem to be missing and have "." as a value, involving the following variables: \textit{departem}, \textit{codeqlt}, \textit{agemvt} and \textit{nbpaiecb}. Many methods exist to handle missing data, one of the easier way is to replace the missing values by the mean, median or mode of the variable. For the two qualitative variables we have chosen the mode, and for the two quantitative variables the median since they are discrete variables (in order to keep the notion of discrete).



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Exploratory Analysis.}

We saw through boxplots that each variable have more or less the same descriptive statistics among samples of one class and samples of the other. It means that none of them, alone, is discriminative according to these criteria. Due to the number of variables and because information given by boxplots is kind of pointless we have decided to not show them here.

The variables do not have at all same range of values, for example, some of them are in francs whereas other represent the age, some normalization could be interesting in the supervised classification.

\begin{figure}[H]
    \centering
    \includesvg[width=\textwidth]{figures/visa_corrplot.svg}
    \caption{Variables correlation for the Visa Premier data set .}
    \label{fig:visa_corrplot}
\end{figure}

Some variables seems to be highly correlated or even completely for some of them.

\begin{table}[H] 
    \centering
    \begin{tabular}{|c|c|c|}
        \hline
        \textit{mteparmo} & \textit{aveparmo} & 0.99 \\
        \textit{aveparfi} & \textit{mtvie} & 0.98 \\
        \textit{aveparfi} & \textit{avtscpte} & 0.95 \\
        \textit{engageml} & \textit{engagemt} & 0.95 \\
        \textit{avtscpte} & \textit{mtvie} & 0.90 \\
        \textit{mteparlo} & \textit{mteparmo} & 0.82 \\
        \textit{mteparlo} & \textit{aveparmo} & 0.82 \\
        \textit{moycredi} & \textit{moycred3} & 0.79 \\
        \textit{nbeparlo} & \textit{nbeparmo} & 0.76 \\
        \hline
    \end{tabular}
    \caption{Highest correlation between variables.}
    \label{tab:visa_corr_table}
\end{table}

\\\\

PCA is a classical method to visualize in two dimensions a data set, but the latter can't take into account qualitative variables. We can however run PCA without these variables and have a pretty good result since we don't have much qualitative variables. Nevertheless, it would have been even better to use an algorithm that can take into account both types of variables, this is the purpose of the FAMD (Factor Analysis of Mixed Data). 

\begin{figure}[H]
    \centering
    \includesvg[width=\textwidth]{figures/famd_ind2.svg}
    \caption{Individuals factor map of FAMD.}
    \label{fig:famd_ind}
\end{figure}

\iffalse
\vspace{-1.25cm}
\begin{figure}[H]
    \centering
    \includesvg[width=\textwidth]{figures/famd_var_quanti.svg}
    \caption{Quantitative variables factor map.}
    \label{fig:famd_var_quanti}
\end{figure}
\fi

%\iffalse
\vspace{-0.25cm}
\begin{figure}[H]
\makebox[\linewidth][c]{%
    \hspace{0.5cm}
    \begin{subfigure}[H]{0.63\textwidth}
        \centering
        \includesvg[width=\textwidth]{figures/famd_var_quanti.svg}
        \caption{Quantitative variables factor map.}
        \label{fig:famd_var_quanti}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[H]{0.63\textwidth}
        \centering
        \includesvg[width=\textwidth]{figures/famd_var_quali.svg}
        \caption{Qualitative variables factor map.}
        \label{fig:famd_var_quali}
    \end{subfigure}%
}
\caption{Variables factor maps of FAMD.}
\label{fig:famd_var}
\end{figure}
%\fi

On the individuals factor map of Figure \ref{famd_ind} we see that both classes are overlapping. The cluster of those who have not the Visa Premier card seems to be "inside" the cluster of those who have it. The latter is more like an ellipsoid than the other (that is more a circle) with a shape kind of ellongated to the right and a little to the top. Therefore we can say that variables that will be highly correlated with the first two components could be important to discriminate them.

We see in the qualitative variables factor map of Figure \ref{fig:famd_var_quali} that this kind of variable seems to not bring much variance to the data since their contribution to the components are much lower than for quantitative variables. However, the modality "A" of the qualitative variable "codeqlt" seems to have a high contribution and is highly correlated with the first component, this variable represents a customer quality defined by the bank.

We found that PCA and FAMD give more or less the same result (for this data set) but the latter gives in addition information about qualitative variables. However, the latter explains less variance (10\%) than PCA (25\%) for the first two components. This can be explained by the fact that qualitative variables are not implicated much in the variance of the data set and that FAMD is bringed down when trying to take into account this kind of variable.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Classification}

At first we have removed the qualitative variables to do a supervised classification with the same algorithms than for synthetic data sets. 

\iffalse
\begin{table}[H] 
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Method} & \textbf{StratifiedKFold} \\
        \hline
        Logistic Regression  & 0.78 $\pm$ 0.05 \\ 
        LDA                  & 0.82 $\pm$ 0.04 \\ 
        QDA                  & 0.45 $\pm$ 0.10 \\ 
        KNN                  & 0.40 $\pm$ 0.13 \\ 
        CART                 & 0.70 $\pm$ 0.20 \\ 
        Gaussian Naive Bayes & 0.76 $\pm$ 0.04 \\ 
        SVM                  & 0.67 $\pm$ 2e-3 \\ 
        AdaBoost             & 0.79 $\pm$ 0.21 \\ 
        GradientBoosting     & 0.82 $\pm$ 0.13 \\ 
        Random Forest        & 0.82 $\pm$ 0.12 \\ 
        ExtraTrees           & \textbf{0.87 $\pm$ 0.03} \\ 
        \hline
    \end{tabular}
    \captionsetup{width=0.85\textwidth}
    \caption{Mean accuracy and standard deviation with k-fold cross-validation ($k=10$).}
    \label{tab:visa_metrics}
\end{table}
\fi

\begin{table}[H] 
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Method} & \textbf{Centroid} & \textbf{NearMiss} & \textbf{Random} \\
        \hline
        Logistic Regression  & 0.83 $\pm$ 0.04 & \textbf{0.91 $\pm$ 0.03} & 0.86 $\pm$ 0.04 \\ 
        LDA                  & 0.81 $\pm$ 0.03 & \textbf{0.88 $\pm$ 0.03} & 0.85 $\pm$ 0.02 \\ 
        QDA                  & 0.57 $\pm$ 0.09 & \textbf{0.80 $\pm$ 0.07} & 0.74 $\pm$ 0.07 \\ 
        KNN                  & 0.76 $\pm$ 0.07 & \textbf{0.84 $\pm$ 0.03} & 0.80 $\pm$ 0.04 \\ 
        CART                 & 0.83 $\pm$ 0.05 & \textbf{0.87 $\pm$ 0.05} & 0.85 $\pm$ 0.04 \\ 
        Gaussian Naive Bayes & 0.71 $\pm$ 0.09 & \textbf{0.83 $\pm$ 0.03} & 0.76 $\pm$ 0.02 \\ 
        SVM                  & 0.85 $\pm$ 0.06 & \textbf{0.90 $\pm$ 0.03} & 0.87 $\pm$ 0.05 \\ 
        AdaBoost             & 0.88 $\pm$ 0.06 & \textbf{0.93 $\pm$ 0.04} & 0.92 $\pm$ 0.04 \\ 
        GradientBoosting     & 0.90 $\pm$ 0.09 & \textbf{0.94 $\pm$ 0.04} & 0.91 $\pm$ 0.08 \\ 
        Random Forest        & 0.88 $\pm$ 0.04 & \textbf{0.93 $\pm$ 0.04} & 0.90 $\pm$ 0.04 \\ 
        ExtraTrees           & 0.87 $\pm$ 0.03 & \textbf{0.95 $\pm$ 0.02} & 0.90 $\pm$ 0.06 \\ 
        \hline
    \end{tabular}
    %\captionsetup{width=0.85\textwidth}
    \caption{Mean accuracy and standard deviation with k-fold cross-validation ($k = 10$) for
three types of under sampling methods.}
    \label{tab:visa_metrics}
\end{table}

\begin{minipage}{\textwidth}
  \hspace{-3.25cm}
  \begin{minipage}[H]{0.63\textwidth}
    \centering
    \includesvg[width=\textwidth]{figures/visa_roc_centroids.svg}
    \captionof{figure}{ROC curves with \textbf{Centroid} under-sampling.}
    \label{fig:visa_roc_random}
  \end{minipage}
  \begin{minipage}[H]{0.63\textwidth}
    \centering
    \includesvg[width=\textwidth]{figures/visa_roc_nearmiss.svg}
    \captionof{figure}{ROC curves with \textbf{NearMiss} under-sampling.}
    \label{fig:visa_roc_random}
  \end{minipage}
\end{minipage}

\begin{minipage}{\textwidth}
  \hspace{-3.25cm}
  \begin{minipage}[H]{0.63\textwidth}
    \centering
    \includesvg[width=\textwidth]{figures/visa_roc_random.svg}
    \captionof{figure}{ROC curves with \textbf{Random} under-sampling.}
    \label{fig:visa_roc_random}
  \end{minipage}
  \hspace{0.25cm}
  \begin{minipage}[H]{0.5\textwidth}
    \centering
    \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Method} & \textbf{Centroid} & \textbf{NearMiss} & \textbf{Random} \\
        \hline
        Logistic Regression  & 0.87 & \textbf{0.97} & 0.91 \\
        LDA                  & 0.87 & \textbf{0.94} & 0.91 \\
        QDA                  & 0.68 & \textbf{0.84} & 0.81\\
        KNN                  & 0.82 & \textbf{0.91} & 0.87 \\
        CART                 & 0.82 & \textbf{0.86} & 0.85 \\
        Gaussian Naive Bayes & 0.77 & \textbf{0.90} & 0.82 \\
        SVM                  & 0.90 & \textbf{0.96} & 0.93 \\
        AdaBoost             & 0.93 & \textbf{0.98} & 0.96 \\
        GradientBoosting     & 0.96 & \textbf{0.98} & 0.97 \\
        Random Forest        & 0.94 & \textbf{0.97} & 0.95 \\
        ExtraTrees           & 0.93 & \textbf{0.97} & 0.95 \\
        \hline
    \end{tabular}
    %\captionsetup{width=0.85\textwidth}
    \captionof{table}{AUC score.}
    \label{tab:visa_auc}
  \end{minipage}
\end{minipage}


